import re
import json
import os
import glob
from collections import defaultdict
from sqllineage.utils.constant import LineageLevel
from sqllineage.runner import LineageRunner
from sqllineage.utils.helpers import split


# Ë°®Á±ªÂûãÊ†áËÆ∞Â∏∏Èáè
class TableTypeMarkers:
    """Ë°®Á±ªÂûãÊ†áËÆ∞Â∏∏ÈáèÔºà‰æø‰∫éÁ®ãÂ∫èÂ§ÑÁêÜÔºâ"""
    TEMP_TABLE_SUFFIX = "_TEMP_TBL"      # ‰∏¥Êó∂Ë°®Ê†áËÆ∞ÂêéÁºÄ
    SUBQUERY_TABLE_SUFFIX = "_SUBQRY_TBL"  # Â≠êÊü•ËØ¢Ë°®Ê†áËÆ∞ÂêéÁºÄ


def extract_temp_tables_from_script(sql_script):
    """
    ‰ªéSQLËÑöÊú¨‰∏≠ÊèêÂèñ‰∏¥Êó∂Ë°®
    Êñ∞ÂÆö‰πâÔºöÊâÄÊúâCREATE TABLEÁöÑË°®ÈÉΩÁÆó‰∏¥Êó∂Ë°®
    """
    # ÊèêÂèñÊâÄÊúâCREATE TABLEÁöÑË°®
    create_pattern = r'CREATE\s+(?:TEMPORARY\s+|TEMP\s+)?(?:TABLE|VIEW)\s+(?:IF\s+NOT\s+EXISTS\s+)?([^\s\(\;]+)'
    create_matches = re.findall(create_pattern, sql_script, re.IGNORECASE | re.MULTILINE)

    # Ê∏ÖÁêÜË°®ÂêçÔºàÂéªÊéâÂºïÂè∑„ÄÅÊñπÊã¨Âè∑Á≠âÔºâ
    def clean_table_name(table_name):
        cleaned = table_name.strip('`"[]').lower()
        # Â¶ÇÊûúÊúâÊï∞ÊçÆÂ∫ìÂâçÁºÄÔºåÂè™‰øùÁïôË°®ÂêçÈÉ®ÂàÜ
        if '.' in cleaned:
            cleaned = cleaned.split('.')[-1]
        return cleaned

    # ÊâÄÊúâCREATE TABLEÁöÑË°®ÈÉΩÁÆó‰∏¥Êó∂Ë°®
    temp_tables = {clean_table_name(table) for table in create_matches}

    print(f"Ê£ÄÊµãÂà∞ÁöÑ‰∏¥Êó∂Ë°®ÔºàÊâÄÊúâCREATE TABLEÔºâ: {temp_tables}")
    return temp_tables


def split_sql_statements(sql_script):
    """
    ‰ΩøÁî®sqllineageÁöÑsplitÊñπÊ≥ïÊù•Ê≠£Á°ÆÊãÜÂàÜSQLËØ≠Âè•
    """
    try:
        statements = split(sql_script)
        return [stmt.strip() for stmt in statements if stmt.strip()]
    except Exception as e:
        print(f"‰ΩøÁî®sqllineageÊãÜÂàÜSQLÂ§±Ë¥•ÔºåÂõûÈÄÄÂà∞ÁÆÄÂçïÊãÜÂàÜ: {e}")
        statements = []
        parts = sql_script.split(';')
        for part in parts:
            part = part.strip()
            if part and not part.isspace():
                statements.append(part)
        return statements


def is_temp_table(table_identifier, temp_tables):
    """
    Ê£ÄÊü•Ë°®ÊòØÂê¶‰∏∫‰∏¥Êó∂Ë°®
    """
    if not table_identifier or not temp_tables:
        return False

    # ÊèêÂèñË°®ÂêçÔºàÂ§ÑÁêÜÂêÑÁßçÊ†ºÂºèÔºâ
    table_name = str(table_identifier).lower()
    if '.' in table_name:
        table_name = table_name.split('.')[-1]

    return table_name in temp_tables


def add_table_type_marker(table_name, is_temp_table, is_subquery_table):
    """
    ‰∏∫Ë°®ÂêçÊ∑ªÂä†Á±ªÂûãÊ†áËÆ∞
    
    Args:
        table_name: ÂéüÂßãË°®Âêç
        is_temp_table: ÊòØÂê¶‰∏∫‰∏¥Êó∂Ë°®
        is_subquery_table: ÊòØÂê¶‰∏∫Â≠êÊü•ËØ¢Ë°®
    
    Returns:
        str: Â∏¶Ê†áËÆ∞ÁöÑË°®Âêç
    """
    if not table_name:
        return table_name
    
    # Â¶ÇÊûúÊòØÂ≠êÊü•ËØ¢Ë°®Ôºå‰ºòÂÖàÊ†áËÆ∞‰∏∫Â≠êÊü•ËØ¢ÔºàÂõ†‰∏∫Â≠êÊü•ËØ¢Ë°®‰πüÂèØËÉΩÊòØ‰∏¥Êó∂ÁöÑÔºâ
    if is_subquery_table:
        return f"{table_name}{TableTypeMarkers.SUBQUERY_TABLE_SUFFIX}"
    elif is_temp_table:
        return f"{table_name}{TableTypeMarkers.TEMP_TABLE_SUFFIX}"
    else:
        return table_name


def extract_database_table_column(column_id, temp_tables, subquery_nodes):
    """
    ‰ªéÂ≠óÊÆµID‰∏≠ÊèêÂèñÊï∞ÊçÆÂ∫ì„ÄÅË°®„ÄÅÂ≠óÊÆµ‰ø°ÊÅØÔºåÂπ∂‰∏∫Ë°®ÂêçÊ∑ªÂä†Á±ªÂûãÊ†áËÆ∞
    ÂÖÅËÆ∏Êï∞ÊçÆÂ∫ìÂêç‰∏∫Á©∫
    """
    if not column_id:
        return None

    parts = str(column_id).split('.')
    
    # ÊèêÂèñÂü∫Êú¨‰ø°ÊÅØ
    if len(parts) >= 3:
        # database.table.column Ê†ºÂºè
        database = parts[0] if parts[0] != '<unknown>' else ''
        table = parts[1]
        column = parts[2]
    elif len(parts) == 2:
        # table.column Ê†ºÂºèÔºàÊó†Êï∞ÊçÆÂ∫ìÂâçÁºÄÔºâ
        database = ''
        table = parts[0]
        column = parts[1]
    elif len(parts) == 1:
        # Âè™ÊúâÂ≠óÊÆµÂêç
        database = ''
        table = ''
        column = parts[0]
    else:
        return None
    
    # Âà§Êñ≠Ë°®Á±ªÂûãÂπ∂Ê∑ªÂä†Ê†áËÆ∞
    if table:
        is_temp = is_temp_table(table, temp_tables)
        is_subquery = table in subquery_nodes
        table_with_marker = add_table_type_marker(table, is_temp, is_subquery)
    else:
        table_with_marker = table
    
    return {
        'database': database,
        'table': table_with_marker,
        'column': column
    }


def trace_lineage_through_subqueries(cytoscape_data, temp_tables):
    """
    Âü∫‰∫ésqllineageÁöÑSubQueryÁ±ªÂûã‰ø°ÊÅØÔºåËøΩË∏™Ë∑®Â≠êÊü•ËØ¢ÁöÑË°ÄÁºòÂÖ≥Á≥ª
    ‰øÆÊîπÔºö‰∏çËøáÊª§‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®ÔºåËÄåÊòØ‰∏∫ÂÆÉ‰ª¨Ê∑ªÂä†Ê†áËÆ∞
    """
    # ÊûÑÂª∫ËäÇÁÇπÂíåËæπÁöÑÊò†Â∞Ñ
    nodes_dict = {}
    edges = []
    subquery_nodes = set()
    
    for item in cytoscape_data:
        data = item.get("data", {})
        item_id = data.get("id", "")
        
        if "source" in data and "target" in data:
            edges.append(data)
        else:
            nodes_dict[item_id] = data
            # ËØÜÂà´SubQueryËäÇÁÇπ
            if data.get("type") == "SubQuery":
                subquery_nodes.add(item_id)
    
    print(f"üîç ÂèëÁé∞ {len(subquery_nodes)} ‰∏™SubQueryËäÇÁÇπ: {subquery_nodes}")
    
    # ÊûÑÂª∫ÂõæÁªìÊûÑÔºöÂá∫ËæπÂíåÂÖ•ËæπÊò†Â∞Ñ
    outgoing_edges = defaultdict(list)  # node_id -> [target_ids]
    incoming_edges = defaultdict(list)  # node_id -> [source_ids]
    
    for edge in edges:
        source_id = edge.get("source", "")
        target_id = edge.get("target", "")
        if source_id and target_id:
            outgoing_edges[source_id].append(target_id)
            incoming_edges[target_id].append(source_id)
    
    # Êî∂ÈõÜÊâÄÊúâË°ÄÁºòË∑ØÂæÑÔºàÂåÖÊã¨‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®Ôºâ
    lineage_paths = []
    
    def is_subquery_column(column_id):
        """Âà§Êñ≠Â≠óÊÆµÊòØÂê¶Â±û‰∫éSubQuery"""
        if not column_id or '.' not in column_id:
            return False
        table_part = column_id.split('.')[0]
        return table_part in subquery_nodes
    
    def is_temp_table_column(column_id):
        """Âà§Êñ≠Â≠óÊÆµÊòØÂê¶Â±û‰∫é‰∏¥Êó∂Ë°®"""
        if not column_id or '.' not in column_id:
            return False
        table_part = column_id.split('.')[0]
        return is_temp_table(table_part, temp_tables)
    
    def is_real_table_column(column_id):
        """Âà§Êñ≠Â≠óÊÆµÊòØÂê¶Â±û‰∫éÁúüÂÆûË°®ÔºàÈùûSubQuery‰∏îÈùû‰∏¥Êó∂Ë°®Ôºâ"""
        if not column_id:
            return False
        
        # È¶ñÂÖàÊ£ÄÊü•ÊòØÂê¶ÊòØSubQueryÂ≠óÊÆµ
        if is_subquery_column(column_id):
            return False
            
        # Ê£ÄÊü•ÊòØÂê¶ÊòØ‰∏¥Êó∂Ë°®Â≠óÊÆµ
        if is_temp_table_column(column_id):
            return False
            
        # Ê£ÄÊü•ËØ•Â≠óÊÆµÁöÑparent_candidates
        column_data = nodes_dict.get(column_id, {})
        parent_candidates = column_data.get("parent_candidates", [])
        
        for candidate in parent_candidates:
            if isinstance(candidate, dict):
                candidate_type = candidate.get("type", "")
                candidate_name = candidate.get("name", "")
                
                # Â¶ÇÊûúparentÊòØTableÁ±ªÂûã‰∏î‰∏çÊòØ‰∏¥Êó∂Ë°®ÔºåÂàôÊòØÁúüÂÆûË°®Â≠óÊÆµ
                if (candidate_type == "Table" and 
                    not is_temp_table(candidate_name, temp_tables)):
                    return True
        
        # Â¶ÇÊûúÊ≤°Êúâparent_candidatesÔºåÈÄöËøáÂ≠óÊÆµIDÂà§Êñ≠
        if '.' in column_id:
            table_part = column_id.split('.')[0]
            return not is_temp_table(table_part, temp_tables)
        
        return False
    
    def trace_through_temp_tables(start_column_id, visited=None):
        """ËøΩË∏™Ë∑®Ë∂ä‰∏¥Êó∂Ë°®ÁöÑË°ÄÁºòÂÖ≥Á≥ªÔºåËøîÂõûÊúÄÁªàÁöÑÁúüÂÆûË°®Â≠óÊÆµ"""
        if visited is None:
            visited = set()
        
        if start_column_id in visited:
            return []  # ÈÅøÂÖçÂæ™ÁéØ
        
        visited.add(start_column_id)
        
        # Â¶ÇÊûúÂΩìÂâçÂ≠óÊÆµÂ∞±ÊòØÁúüÂÆûË°®Â≠óÊÆµÔºåÁõ¥Êé•ËøîÂõû
        if is_real_table_column(start_column_id):
            return [start_column_id]
        
        # Â¶ÇÊûúÊòØ‰∏¥Êó∂Ë°®Â≠óÊÆµÊàñSubQueryÂ≠óÊÆµÔºåÁªßÁª≠ËøΩË∏™ÂÖ∂Ê∫êÂ≠óÊÆµ
        real_sources = []
        for source_id in incoming_edges.get(start_column_id, []):
            deeper_sources = trace_through_temp_tables(source_id, visited.copy())
            real_sources.extend(deeper_sources)
        
        return real_sources
    
    def trace_to_real_source(subquery_column_id, visited=None):
        """‰ªéÂ≠êÊü•ËØ¢Â≠óÊÆµËøΩË∏™Âà∞ÁúüÂÆûÊ∫êË°®Â≠óÊÆµ"""
        if visited is None:
            visited = set()
        
        if subquery_column_id in visited:
            return []  # ÈÅøÂÖçÂæ™ÁéØ
        
        visited.add(subquery_column_id)
        real_sources = []
        
        # Êü•ÊâæËØ•Â≠êÊü•ËØ¢Â≠óÊÆµÁöÑÊâÄÊúâÊ∫êÂ≠óÊÆµ
        for source_id in incoming_edges.get(subquery_column_id, []):
            if is_subquery_column(source_id):
                # Â¶ÇÊûúÊ∫êËøòÊòØÂ≠êÊü•ËØ¢Â≠óÊÆµÔºåÁªßÁª≠ÈÄíÂΩíËøΩË∏™
                deeper_sources = trace_to_real_source(source_id, visited.copy())
                real_sources.extend(deeper_sources)
            elif is_real_table_column(source_id):
                # Â¶ÇÊûúÊ∫êÊòØÁúüÂÆûË°®Â≠óÊÆµÔºåÊ∑ªÂä†Âà∞ÁªìÊûú
                real_sources.append(source_id)
            elif is_temp_table_column(source_id):
                # Â¶ÇÊûúÊ∫êÊòØ‰∏¥Êó∂Ë°®Â≠óÊÆµÔºåËøΩË∏™Âà∞ÁúüÂÆûË°®
                deeper_sources = trace_through_temp_tables(source_id, visited.copy())
                real_sources.extend(deeper_sources)
        
        return real_sources
    
    # Â§ÑÁêÜÁ≠ñÁï•ÔºöÊî∂ÈõÜÊâÄÊúâË°ÄÁºòÂÖ≥Á≥ªÔºåÂåÖÊã¨Ê∂âÂèä‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®ÁöÑ
    
    if subquery_nodes:
        # ÊúâSubQueryÁöÑÊÉÖÂÜµÔºöÂ§ÑÁêÜË∑®SubQueryÁöÑË°ÄÁºòÂÖ≥Á≥ª
        processed_subquery_columns = set()
        
        for edge in edges:
            source_id = edge.get("source", "")
            target_id = edge.get("target", "")
            
            # Â§ÑÁêÜ SubQueryÂ≠óÊÆµ ‚Üí ÊúÄÁªàË°®Â≠óÊÆµ ÁöÑËæπ
            if (is_subquery_column(source_id) and 
                not is_subquery_column(target_id) and  # ÁõÆÊ†á‰∏çÊòØÂ≠êÊü•ËØ¢Â≠óÊÆµ
                source_id not in processed_subquery_columns):
                
                processed_subquery_columns.add(source_id)
                
                # ËøΩË∏™ËØ•SubQueryÂ≠óÊÆµÁöÑÁúüÂÆûÊ∫êË°®
                real_sources = trace_to_real_source(source_id)
                
                # Âª∫Á´ãÁúüÂÆûÊ∫êË°®Âà∞ÊúÄÁªàÁõÆÊ†áË°®ÁöÑË°ÄÁºòÂÖ≥Á≥ª
                for real_source_id in real_sources:
                    lineage_paths.append({
                        'source': real_source_id,
                        'target': target_id
                    })
                    print(f"üîó Âª∫Á´ãË°ÄÁºòË∑ØÂæÑ: {real_source_id} ‚Üí {target_id} (Ë∑®Ë∂äSubQuery: {source_id})")
    
    # Â§ÑÁêÜÊâÄÊúâÁõ¥Êé•ÁöÑÂ≠óÊÆµÂà∞Â≠óÊÆµÁöÑËæπÔºàÂåÖÊã¨‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®Ôºâ
    for edge in edges:
        source_id = edge.get("source", "")
        target_id = edge.get("target", "")
        
        # Êî∂ÈõÜÊâÄÊúâÁõ¥Êé•ÁöÑË°ÄÁºòÂÖ≥Á≥ªÔºà‰∏çÂÜçËøáÊª§‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®Ôºâ
        if source_id and target_id and '.' in source_id and '.' in target_id:
            lineage_paths.append({
                'source': source_id,
                'target': target_id
            })
            print(f"üîó Áõ¥Êé•Ë°ÄÁºòË∑ØÂæÑ: {source_id} ‚Üí {target_id}")
    
    print(f"üéØ ÊÄªÂÖ±ËøΩË∏™Âà∞ {len(lineage_paths)} Êù°Ë°ÄÁºòË∑ØÂæÑ")
    
    return lineage_paths, subquery_nodes


def process_cytoscape_lineage(cytoscape_data, temp_tables, unused_param, etl_system, etl_job, sql_path, sql_no):
    """
    Â§ÑÁêÜcytoscapeÊ†ºÂºèÁöÑË°ÄÁºòÊï∞ÊçÆ
    ‰øÆÊîπÔºö‰∏çËøáÊª§‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®ÔºåËÄåÊòØ‰∏∫ÂÆÉ‰ª¨Ê∑ªÂä†Ê†áËÆ∞
    """
    lineage_records = []

    if not cytoscape_data:
        return lineage_records

    print("üîç ‰ΩøÁî®Âü∫‰∫ésqllineageÁöÑSubQueryÂ§ÑÁêÜÁÆóÊ≥ïÔºàÂ∏¶Ê†áËÆ∞ÁâàÊú¨Ôºâ")
    # ‰ΩøÁî®Âü∫‰∫ésqllineage SubQueryÁ±ªÂûãÁöÑËøΩË∏™ÁÆóÊ≥ï
    lineage_paths, subquery_nodes = trace_lineage_through_subqueries(cytoscape_data, temp_tables)
    
    for path in lineage_paths:
        source_id = path['source']
        target_id = path['target']
        
        # Ëß£ÊûêÊ∫êÂ≠óÊÆµ‰ø°ÊÅØÔºà‰ºöËá™Âä®Ê∑ªÂä†Ê†áËÆ∞Ôºâ
        source_info = extract_database_table_column(source_id, temp_tables, subquery_nodes)
        if not source_info or not source_info['table']:
            continue
        
        # Ëß£ÊûêÁõÆÊ†áÂ≠óÊÆµ‰ø°ÊÅØÔºà‰ºöËá™Âä®Ê∑ªÂä†Ê†áËÆ∞Ôºâ
        target_info = extract_database_table_column(target_id, temp_tables, subquery_nodes)
        if not target_info or not target_info['table']:
            continue
        
        # ‰∏çÂÜçË∑≥Ëøá‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®ÔºåÁõ¥Êé•Ê∑ªÂä†Ë°ÄÁºòËÆ∞ÂΩïÔºàË°®ÂêçÂ∑≤Â∏¶Ê†áËÆ∞Ôºâ
        record = {
            'etl_system': etl_system,
            'etl_job': etl_job,
            'sql_path': sql_path,
            'sql_no': sql_no,
            'source_database': source_info['database'],
            'source_table': source_info['table'],  # Â∑≤ÂåÖÂê´Ê†áËÆ∞
            'source_column': source_info['column'],
            'target_database': target_info['database'],
            'target_table': target_info['table'],  # Â∑≤ÂåÖÂê´Ê†áËÆ∞
            'target_column': target_info['column']
        }
        
        lineage_records.append(record)
    
    print(f"‚úÖ Ëß£ÊûêÂá∫ {len(lineage_records)} Êù°Â≠óÊÆµÁ∫ßË°ÄÁºòÂÖ≥Á≥ªÔºàÂåÖÂê´Ê†áËÆ∞ÁöÑ‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®Ôºâ")
    return lineage_records


# DDLÂíåÊéßÂà∂ËØ≠Âè•Á±ªÂûãÂ∏∏Èáè
class DDLStatementTypes:
    """‰∏çÈúÄË¶ÅËß£ÊûêË°ÄÁºòÂÖ≥Á≥ªÁöÑËØ≠Âè•Á±ªÂûãÔºàÁ±ª‰ººJavaÈùôÊÄÅÁ±ª/Êûö‰∏æÔºâ"""
    
    # ‰∏çÈúÄË¶ÅËß£ÊûêË°ÄÁºòÂÖ≥Á≥ªÁöÑËØ≠Âè•ÂÖ≥ÈîÆÂ≠ó
    SKIP_KEYWORDS = frozenset([
        'ALTER', 'DROP', 'USE', 'GRANT', 'REVOKE', 'SET', 'SHOW', 
        'DESCRIBE', 'DESC', 'EXPLAIN', 'ANALYZE', 'TRUNCATE', 
        'COMMENT', 'REFRESH', 'MSCK', 'CACHE', 'UNCACHE',
        'CREATE DATABASE', 'CREATE SCHEMA', 'CREATE USER', 'CREATE ROLE', 
        'CREATE INDEX', 'CREATE FUNCTION', 'CREATE PROCEDURE'
    ])


def is_ddl_or_control_statement(sql_statement):
    """
    Ê£ÄÊµãSQLËØ≠Âè•ÊòØÂê¶‰∏∫‰∏çÈúÄË¶ÅËß£ÊûêË°ÄÁºòÂÖ≥Á≥ªÁöÑËØ≠Âè•
    ÁÆÄÂåñÁâàÔºöÂè™Ë∑≥ËøáÁúüÊ≠£‰∏çÈúÄË¶ÅËß£ÊûêÁöÑËØ≠Âè•ÔºåÊúâË°ÄÁºòÂÖ≥Á≥ªÁöÑCREATE TABLE AS SELECTÁ≠âÂ∫îËØ•Ê≠£Â∏∏Ëß£Êûê
    """
    if not sql_statement or not sql_statement.strip():
        return False, None
    
    # ÁÆÄÂçïÂàÜËØçÂ§ÑÁêÜÔºàÂÅáËÆæËæìÂÖ•Â∑≤Ê∏ÖÁêÜËøáÊ≥®ÈáäÔºâ
    sql_upper = sql_statement.strip().upper()
    words = sql_upper.split()
    
    if not words:
        return False, None
    
    # Ê£ÄÊü•ÂçïÂÖ≥ÈîÆËØçËØ≠Âè•
    first_word = words[0]
    if first_word in DDLStatementTypes.SKIP_KEYWORDS:
        return True, first_word
    
    # Ê£ÄÊü•‰∏§ÂÖ≥ÈîÆËØçÁªÑÂêàËØ≠Âè•
    if len(words) >= 2:
        two_words = f"{words[0]} {words[1]}"
        if two_words in DDLStatementTypes.SKIP_KEYWORDS:
            return True, two_words
    
    # ÁâπÊÆäÂ§ÑÁêÜCREATEËØ≠Âè•
    if first_word == 'CREATE' and len(words) >= 2:
        second_word = words[1]
        
        # CREATE TABLE/VIEW ËØ≠Âè•ÁªÜÂàÜ
        if second_word in ('TABLE', 'VIEW') or (second_word in ('TEMPORARY', 'TEMP') and len(words) >= 3 and words[2] in ('TABLE', 'VIEW')):
            # Â¶ÇÊûúÂåÖÂê´ASÂÖ≥ÈîÆÂ≠óÔºåËØ¥ÊòéÊòØCREATE TABLE AS SELECTÔºåÊúâË°ÄÁºòÂÖ≥Á≥ªÔºåÈúÄË¶ÅËß£Êûê
            if 'AS' in words and 'SELECT' in words:
                return False, None  # ‰∏çË∑≥ËøáÔºåÈúÄË¶ÅËß£ÊûêË°ÄÁºòÂÖ≥Á≥ª
            else:
                # Á∫ØCREATE TABLEÂÆö‰πâËØ≠Âè•ÔºåÊó†Ë°ÄÁºòÂÖ≥Á≥ªÔºåË∑≥Ëøá
                if second_word in ('TEMPORARY', 'TEMP'):
                    return True, f'CREATE {second_word} {words[2]}'
                else:
                    return True, f'CREATE {second_word}'
    
    # ÂÖ∂‰ªñËØ≠Âè•ÔºàINSERT„ÄÅSELECTÁ≠âÔºâÈÉΩ‰∏çË∑≥ËøáÔºåÊ≠£Â∏∏Ëß£ÊûêË°ÄÁºòÂÖ≥Á≥ª
    return False, None


def process_single_sql(sql_statement, temp_tables, etl_system, etl_job, sql_path, sql_no, db_type='oracle'):
    """
    Â§ÑÁêÜÂçïÊù°SQLËØ≠Âè•ÔºåËé∑ÂèñË°ÄÁºòÂÖ≥Á≥ª
    """
    lineage_records = []
    
    # È¶ñÂÖàÊ£ÄÊü•ÊòØÂê¶‰∏∫DDLÊàñÊéßÂà∂ËØ≠Âè•
    is_ddl, stmt_type = is_ddl_or_control_statement(sql_statement)
    
    if is_ddl:
        print(f"‚è≠Ô∏è  Ë∑≥Ëøá{stmt_type}ËØ≠Âè•ÔºàÊó†Ë°ÄÁºòÂÖ≥Á≥ªËß£ÊûêÊÑè‰πâÔºâ")
        return lineage_records
    
    try:
        # ‰ΩøÁî®LineageRunnerÂàÜÊûêSQL
        runner = LineageRunner(sql_statement, dialect=db_type, silent_mode=True)

        # Ëé∑ÂèñcytoscapeÊ†ºÂºèÁöÑÂ≠óÊÆµÁ∫ßË°ÄÁºòÊï∞ÊçÆ
        try:
            cytoscape_data = runner.to_cytoscape(LineageLevel.COLUMN)
            
            if cytoscape_data and isinstance(cytoscape_data, list):
                lineage_records = process_cytoscape_lineage(cytoscape_data, temp_tables, None, etl_system, etl_job, sql_path, sql_no)
                print(f"‚úÖ Ëß£ÊûêÂá∫ {len(lineage_records)} Êù°Â≠óÊÆµÁ∫ßË°ÄÁºòÂÖ≥Á≥ª")
            else:
                print("‚ùå Êú™Ëé∑ÂèñÂà∞Â≠óÊÆµÁ∫ßË°ÄÁºòÊï∞ÊçÆ")

        except Exception as e:
            print(f"‚ùå Ëé∑ÂèñÂ≠óÊÆµÁ∫ßË°ÄÁºòÂ§±Ë¥•: {e}")

    except Exception as e:
        print(f"‚ùå ÂàõÂª∫LineageRunnerÊó∂Âá∫Èîô: {e}")

    return lineage_records


def generate_oracle_insert_statements(lineage_records):
    """
    ÁîüÊàêOracle INSERTËØ≠Âè•ÔºàÂåÖÂê´etl_system„ÄÅetl_job„ÄÅsql_path„ÄÅsql_noÂ≠óÊÆµÔºâ
    
    Args:
        lineage_records: Ë°ÄÁºòÂÖ≥Á≥ªËÆ∞ÂΩïÂàóË°®
        
    Returns:
        str: Oracle INSERTËØ≠Âè•
    """
    if not lineage_records:
        return "-- Ê≤°ÊúâÊâæÂà∞Ë°ÄÁºòÂÖ≥Á≥ªÊï∞ÊçÆ"

    insert_statements = []
    insert_statements.append("-- SQLË°ÄÁºòÂÖ≥Á≥ªÊï∞ÊçÆÊèíÂÖ•ËØ≠Âè•ÔºàÂåÖÂê´Ê†áËÆ∞ÁöÑ‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®Ôºâ")
    insert_statements.append("-- Ë°®ÁªìÊûÑ: ETL_SYSTEM, ETL_JOB, SQL_PATH, SQL_NO, SOURCE_DATABASE, SOURCE_SCHEMA, SOURCE_TABLE, SOURCE_COLUMN, TARGET_DATABASE, TARGET_SCHEMA, TARGET_TABLE, TARGET_COLUMN")
    insert_statements.append(f"-- ‰∏¥Êó∂Ë°®Ê†áËÆ∞ÂêéÁºÄ: {TableTypeMarkers.TEMP_TABLE_SUFFIX}")
    insert_statements.append(f"-- Â≠êÊü•ËØ¢Ë°®Ê†áËÆ∞ÂêéÁºÄ: {TableTypeMarkers.SUBQUERY_TABLE_SUFFIX}")
    insert_statements.append("")

    for record in lineage_records:
        def format_value(value):
            if not value or value == '':
                return 'NULL'
            else:
                escaped_value = str(value).replace("'", "''")
                return f"'{escaped_value}'"

        etl_system = format_value(record['etl_system'])
        etl_job = format_value(record['etl_job'])
        sql_path = format_value(record['sql_path'])
        sql_no = record['sql_no'] if record['sql_no'] is not None else 'NULL'
        source_db = format_value(record['source_database'])
        source_table = format_value(record['source_table'])
        source_column = format_value(record['source_column'])
        target_db = format_value(record['target_database'])
        target_table = format_value(record['target_table'])
        target_column = format_value(record['target_column'])

        insert_sql = f"""INSERT INTO LINEAGE_TABLE (ETL_SYSTEM, ETL_JOB, SQL_PATH, SQL_NO, SOURCE_DATABASE, SOURCE_SCHEMA, SOURCE_TABLE, SOURCE_COLUMN, TARGET_DATABASE, TARGET_SCHEMA, TARGET_TABLE, TARGET_COLUMN)
VALUES ({etl_system}, {etl_job}, {sql_path}, {sql_no}, {source_db}, {source_db}, {source_table}, {source_column}, {target_db}, {target_db}, {target_table}, {target_column});"""

        insert_statements.append(insert_sql)

    insert_statements.append("")
    insert_statements.append("COMMIT;")

    return "\n".join(insert_statements)


def process_sql_script(sql_script, etl_system='', etl_job='', sql_path='', db_type='oracle'):
    """
    Â§ÑÁêÜSQLËÑöÊú¨ÔºàÊîØÊåÅÂçïÊù°SQLÊàñÂÆåÊï¥ËÑöÊú¨Ôºâ
    """
    print("=== ÂºÄÂßãÂ§ÑÁêÜSQLËÑöÊú¨ÔºàÊ†áËÆ∞ÁâàÊú¨Ôºâ===")

    # 1. ÊèêÂèñ‰∏¥Êó∂Ë°®
    temp_tables = extract_temp_tables_from_script(sql_script)

    # 2. ÊãÜÂàÜSQLËØ≠Âè•
    sql_statements = split_sql_statements(sql_script)
    print(f"ÂÖ±ÊâæÂà∞ {len(sql_statements)} Êù°SQLËØ≠Âè•")

    # 3. Â§ÑÁêÜÊØèÊù°SQL
    all_lineage_records = []
    for i, sql in enumerate(sql_statements):
        sql_no = i + 1
        print(f"Â§ÑÁêÜÁ¨¨ {sql_no}/{len(sql_statements)} Êù°SQL...")
        
        lineage_records = process_single_sql(sql, temp_tables, etl_system, etl_job, sql_path, sql_no, db_type)
        all_lineage_records.extend(lineage_records)
        
        print(f"  Êñ∞Â¢û {len(lineage_records)} Êù°Ë°ÄÁºòÂÖ≥Á≥ª")

    print(f"ÂÖ±ÊèêÂèñÂà∞ {len(all_lineage_records)} Êù°Ë°ÄÁºòÂÖ≥Á≥ªÔºàÂåÖÂê´Ê†áËÆ∞ÁöÑ‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®Ôºâ")

    # 4. ÁîüÊàêOracle INSERTËØ≠Âè•
    oracle_statements = generate_oracle_insert_statements(all_lineage_records)

    return oracle_statements


def lineage_analysis(sql=None, file=None, db_type='oracle'):
    """
    Ë°ÄÁºòÂÖ≥Á≥ªÂàÜÊûê‰∏ªÂÖ•Âè£ÔºàÊ†áËÆ∞ÁâàÊú¨Ôºâ
    
    Args:
        sql: SQLËÑöÊú¨ÂÜÖÂÆπÂ≠óÁ¨¶‰∏≤
        file: SQLÊñá‰ª∂Ë∑ØÂæÑÔºàÂçï‰∏™Êñá‰ª∂ÊàñÁõÆÂΩïÔºâ
        db_type: Êï∞ÊçÆÂ∫ìÁ±ªÂûãÔºåÈªòËÆ§'oracle'
        
    Returns:
        str: Oracle INSERTËØ≠Âè•ÔºàÂåÖÂê´Ê†áËÆ∞ÁöÑ‰∏¥Êó∂Ë°®ÂíåÂ≠êÊü•ËØ¢Ë°®Ôºâ
    """
    
    if sql is not None and file is not None:
        raise ValueError("sqlÂíåfileÂèÇÊï∞‰∏çËÉΩÂêåÊó∂Êèê‰æõÔºåÂè™ËÉΩÈÄâÊã©ÂÖ∂‰∏≠‰∏Ä‰∏™")
    
    if sql is None and file is None:
        raise ValueError("ÂøÖÈ°ªÊèê‰æõsqlÊàñfileÂèÇÊï∞")

    if sql is not None:
        # Â§ÑÁêÜSQLÂ≠óÁ¨¶‰∏≤
        print("=== Â§ÑÁêÜSQLÂ≠óÁ¨¶‰∏≤ÔºàÊ†áËÆ∞ÁâàÊú¨Ôºâ===")
        return process_sql_script(sql, db_type=db_type)
        
    elif file is not None:
        # Â§ÑÁêÜÊñá‰ª∂Ë∑ØÂæÑ
        print(f"=== Â§ÑÁêÜÊñá‰ª∂Ë∑ØÂæÑÔºàÊ†áËÆ∞ÁâàÊú¨Ôºâ: {file} ===")
        
        if os.path.isfile(file):
            # Â§ÑÁêÜÂçï‰∏™Êñá‰ª∂
            try:
                with open(file, 'r', encoding='utf-8') as f:
                    sql_content = f.read()
                
                etl_system = os.path.basename(os.path.dirname(file))
                etl_job = os.path.splitext(os.path.basename(file))[0]
                
                return process_sql_script(sql_content, etl_system, etl_job, file, db_type)
                
            except Exception as e:
                return f"-- Â§ÑÁêÜÊñá‰ª∂Â§±Ë¥•: {e}"
                
        elif os.path.isdir(file):
            # Â§ÑÁêÜÁõÆÂΩï
            sql_extensions = ['*.sql', '*.SQL', '*.hql', '*.HQL']
            all_results = []
            
            etl_system = os.path.basename(os.path.abspath(file))
            
            # ‰ΩøÁî®ÈõÜÂêàÂéªÈáçÔºåÈÅøÂÖçWindowsÁ≥ªÁªü‰∏≠Â§ßÂ∞èÂÜô‰∏çÊïèÊÑüÂØºËá¥ÁöÑÈáçÂ§çÊñá‰ª∂
            all_files = set()
            for ext in sql_extensions:
                pattern = os.path.join(file, '**', ext)
                files = glob.glob(pattern, recursive=True)
                all_files.update(files)
            
            # ËΩ¨Êç¢‰∏∫ÂàóË°®Âπ∂ÊéíÂ∫èÔºåÁ°Æ‰øùÂ§ÑÁêÜÈ°∫Â∫è‰∏ÄËá¥
            sql_files = sorted(list(all_files))
            file_count = len(sql_files)
            
            if file_count == 0:
                return "-- Êú™ÊâæÂà∞‰ªª‰ΩïSQLÊñá‰ª∂"
            
            print(f"ÊâæÂà∞ {file_count} ‰∏™SQLÊñá‰ª∂")
            
            for i, sql_file in enumerate(sql_files):
                try:
                    print(f"\nÂ§ÑÁêÜÊñá‰ª∂ {i+1}/{file_count}: {sql_file}")
                    
                    with open(sql_file, 'r', encoding='utf-8') as f:
                        sql_content = f.read()
                    
                    etl_job = os.path.splitext(os.path.basename(sql_file))[0]
                    
                    result = process_sql_script(sql_content, etl_system, etl_job, sql_file, db_type)
                    all_results.append(result)
                    
                except Exception as e:
                    print(f"Â§ÑÁêÜÊñá‰ª∂ {sql_file} Â§±Ë¥•: {e}")
                    all_results.append(f"-- Êñá‰ª∂: {sql_file}\n-- Â§ÑÁêÜÂ§±Ë¥•: {e}")
            
            # ÂêàÂπ∂ÁªìÊûú
            combined_result = []
            combined_result.append(f"-- ÂÖ±Â§ÑÁêÜ {file_count} ‰∏™Êñá‰ª∂")
            combined_result.append("")
            
            for result in all_results:
                combined_result.append(result)
                combined_result.append("")
            
            return "\n".join(combined_result)
        else:
            return f"-- Ë∑ØÂæÑ‰∏çÂ≠òÂú®: {file}"


if __name__ == "__main__":
    
    # ÊµãËØïSQLÁ§∫‰æã
    test_sql = """
    CREATE TEMPORARY TABLE temp_sales AS (
        SELECT customer_id, SUM(amount) as total_amount
        FROM orders
        WHERE order_date >= '2023-01-01'
    );
    
    INSERT INTO customer_summary (customer_id, total_purchase, last_update)
    SELECT 
        t.customer_id,
        t.total_amount,
        SYSDATE
    FROM temp_sales t
    JOIN customers c ON t.customer_id = c.id
    WHERE c.status = 'ACTIVE';
    """
    
    result = lineage_analysis(sql=test_sql, db_type='oracle')
    print("ÁªìÊûú:")
    print(result) 